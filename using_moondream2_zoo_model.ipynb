{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Moondream2 as Remotely Sourced Zoo Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing directory '/home/harpreet/fiftyone/quickstart'\n",
      "Downloading dataset to '/home/harpreet/fiftyone/quickstart'\n",
      "Downloading dataset...\n",
      " 100% |████|  187.5Mb/187.5Mb [451.4ms elapsed, 0s remaining, 415.5Mb/s]      \n",
      "Extracting dataset...\n",
      "Parsing dataset metadata\n",
      "Found 200 samples\n",
      "Dataset info written to '/home/harpreet/fiftyone/quickstart/info.json'\n",
      "Loading existing dataset 'quickstart'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "# Load a dataset\n",
    "dataset = foz.load_zoo_dataset(\"quickstart\", overwrite=True)\n",
    "dataset=dataset.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Zoo Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fiftyone as fo\n",
    "# import fiftyone.zoo as foz\n",
    "# foz.register_zoo_model_source(\"https://github.com/harpreetsahota204/moondream2\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "foz.download_zoo_model(\n",
    "    \"https://github.com/harpreetsahota204/moondream2\",\n",
    "    model_name=\"vikhyatk/moondream2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae89429e4f6a40e2a4412183c1173bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading moondream2 model from /home/harpreet/fiftyone/__models__/moondream2/moondream2\n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "model = foz.load_zoo_model(\n",
    "    \"vikhyatk/moondream2\",\n",
    "    revision=\"2025-03-27\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Moondream2 for Captions\n",
    "\n",
    "The three captioning operations require no additional arguments beyond selecting the operation type. \n",
    "\n",
    "Supported `length` values:\n",
    "\n",
    "* `short`\n",
    "\n",
    "* `normal`\n",
    "\n",
    "* `long`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████████████| 3/3 [7.4s elapsed, 0s remaining, 0.4 samples/s]   \n"
     ]
    }
   ],
   "source": [
    "model.set_operation(operation=\"caption\", length= \"long\")\n",
    "\n",
    "dataset.apply_model(\n",
    "    model, \n",
    "    label_field=\"captions\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The image shows a woman standing outdoors, holding a black umbrella in her right hand and smiling at the camera. She is wearing a beige trench coat, blue jeans, and flat shoes, and she has a black handbag slung over her left shoulder. The woman appears to be posing for a photograph, standing confidently on a wooden deck or platform made of planks. Behind her, there is a unique architectural structure composed of wooden beams and panels, creating an artistic and visually appealing setting. The structure has a translucent, semi-transparent glass covering, allowing natural light to filter through and creating an ethereal atmosphere.\\n\\nIn the background, there is a serene park-like setting with lush green grass, trees, and a calm body of water visible behind the structure. The water appears still and reflective, adding to the peaceful ambiance. Further in the distance, there are buildings and structures, indicating an urban or suburban environment. The overall color palette of the image is soft and natural, with shades of beige, brown, green, and black, creating a calm and inviting atmosphere.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.first()['captions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Moondream2 for Detection\n",
    "\n",
    "\n",
    "The results are stored as Detections objects containing bounding boxes and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████████████| 3/3 [779.1ms elapsed, 0s remaining, 3.9 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "model.set_operation(\n",
    "    operation=\"detect\",\n",
    "    object_type=\"people\",\n",
    ")\n",
    "\n",
    "dataset.apply_model(\n",
    "    model,\n",
    "    label_field=\"detections\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Detections: {\n",
       "    'detections': [\n",
       "        <Detection: {\n",
       "            'id': '67e84283c0b17942fc9c06c4',\n",
       "            'attributes': {},\n",
       "            'tags': [],\n",
       "            'label': 'people',\n",
       "            'bounding_box': [\n",
       "                0.36569203436374664,\n",
       "                0.3885642886161804,\n",
       "                0.2686159312725067,\n",
       "                0.6056839227676392,\n",
       "            ],\n",
       "            'mask': None,\n",
       "            'mask_path': None,\n",
       "            'confidence': None,\n",
       "            'index': None,\n",
       "        }>,\n",
       "    ],\n",
       "}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.first()['detections']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Moondream2 for Keypoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████████████| 3/3 [684.1ms elapsed, 0s remaining, 4.4 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "model.set_operation(    \n",
    "    operation=\"point\",\n",
    "    object_type=\"people\",)\n",
    "\n",
    "# Apply with a different operation\n",
    "dataset.apply_model(\n",
    "    model,\n",
    "    label_field=\"pointings\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Keypoints: {\n",
       "    'keypoints': [\n",
       "        <Keypoint: {\n",
       "            'id': '67e842c6c0b17942fc9c06d1',\n",
       "            'attributes': {},\n",
       "            'tags': [],\n",
       "            'label': 'people',\n",
       "            'points': [[0.4873046875, 0.5712890625]],\n",
       "            'confidence': None,\n",
       "            'index': None,\n",
       "        }>,\n",
       "    ],\n",
       "}>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.first()['pointings']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Moondream2 for VQA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████████████| 3/3 [1.0s elapsed, 0s remaining, 2.9 samples/s]         \n"
     ]
    }
   ],
   "source": [
    "model.set_operation(    \n",
    "    operation=\"query\",\n",
    "    query_text=\"What is the in the background of the image\",)\n",
    "\n",
    "dataset.apply_model(\n",
    "    model,\n",
    "    label_field=\"query_text_response\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' In the background of the image, there is a body of water, possibly a lake or a pond, and a building.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.first()['query_text_response']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you want to use a Field of a Sample for grounding, you use the following pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.add_sample_field(\"questions\")\n",
    "\n",
    "dataset.set_values(\"questions\", [\"Where is the general location of this scene?\"]*len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Where is the general location of this scene?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.first()['questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████████████| 3/3 [1.0s elapsed, 0s remaining, 2.9 samples/s]         \n"
     ]
    }
   ],
   "source": [
    "model.set_operation(    \n",
    "    operation=\"query\",\n",
    "    query_field=\"questions\"\n",
    "    )\n",
    "\n",
    "\n",
    "dataset.apply_model(\n",
    "    model,\n",
    "    label_field=\"query_field_response\",\n",
    "    query_field=\"questions\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The general location of this scene is a park, where the woman is standing under a large umbrella.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.first()['query_field_response']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiftyone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
